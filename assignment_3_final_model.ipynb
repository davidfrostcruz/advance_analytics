{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.46.210.116:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.46.210.116:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc7d03d5fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section corresponds to loading the collected data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+-----+\n",
      "|review_id| app_id|         review_text|label|\n",
      "+---------+-------+--------------------+-----+\n",
      "|138827659| 824600|Very fun boomer s...|    1|\n",
      "|138825357| 824600|I kept squeezing ...|    1|\n",
      "|138826496|2412700|Good game, some m...|    1|\n",
      "|138828398|1268750|I'M DOING MY PART...|    1|\n",
      "|138828252|1268750|Honestly fun and ...|    1|\n",
      "|138828203|1268750|I'm playing my fa...|    1|\n",
      "|138827799|1268750|it I'm part doing!!!|    1|\n",
      "|138827540|1268750|Do you like Stars...|    1|\n",
      "|138827272|1268750|My review of this...|    1|\n",
      "|138827016|1268750|COME ON YOU APES!...|    1|\n",
      "|138826983|1268750|I don't understan...|    0|\n",
      "|138826753|1268750|   I'M DOING MY PART|    1|\n",
      "|138827015|1724770|An Epic Tower Def...|    1|\n",
      "|138826634|1724770|Tower Defence is ...|    1|\n",
      "|138827455|1934780|Really good game,...|    1|\n",
      "|138827269|2370310|A laid-back but s...|    1|\n",
      "|138828505|1304930|Considering that ...|    1|\n",
      "|138828184|1304930|I can now shit my...|    1|\n",
      "|138828143|1304930|Absolutely stress...|    1|\n",
      "|138827821|1304930|Mother Gooseberry...|    1|\n",
      "+---------+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory path where the JSON files are located\n",
    "directory = '/Users/davidfrost/Documents/analytics/a3/spark/notebooks/data' # Add path\n",
    "\n",
    "# Define the schema for the JSON files\n",
    "schema = StructType([\n",
    "    StructField(\"review_id\", StringType(), True),\n",
    "    StructField(\"app_id\", StringType(), True),\n",
    "    StructField(\"review_text\", StringType(), True),\n",
    "    StructField(\"label\", IntegerType(), True),\n",
    "    # Add more fields as needed\n",
    "])\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.endswith('.json'):\n",
    "        new_filename = os.path.join(directory, filename + '.json')\n",
    "        old_filepath = os.path.join(directory, filename)\n",
    "        new_filepath = os.path.join(directory, new_filename)\n",
    "        \n",
    "        # Check if the destination file already exists\n",
    "        if not os.path.exists(new_filepath):\n",
    "            os.rename(old_filepath, new_filepath)\n",
    "        \n",
    "# Get a list of JSON file paths excluding _SUCCESS files and empty files\n",
    "file_paths = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json') and filename != '_SUCCESS':\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.getsize(file_path) > 0:  # Check if the file is not empty\n",
    "            file_paths.append(file_path)\n",
    "\n",
    "# Read JSON files from the directory into a DataFrame with the specified schema\n",
    "df = spark.read.schema(schema).json(file_paths)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 1868\n"
     ]
    }
   ],
   "source": [
    "# Total observations\n",
    "num_observations = df.count()\n",
    "print(\"Number of observations:\", num_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the model training is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/27 19:39:36 ERROR LBFGS: Failure! Resetting history: breeze.optimize.StepSizeUnderflow: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/27 19:39:54 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Define the stages of the pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"tokens\")\n",
    "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
    "cv = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, lr])\n",
    "\n",
    "# Train the model\n",
    "logreg = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8027027027027027\n",
      "Precision: 0.8460758607597941\n",
      "Recall: 0.8027027027027026\n",
      "F1 Score: 0.8170861314064869\n",
      "Area Under ROC: 0.8333579626619378\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = logreg.transform(test_data)\n",
    "\n",
    "# BinaryClassificationEvaluator\n",
    "binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "\n",
    "# MulticlassClassificationEvaluator\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "\n",
    "# Evaluate the model and obtain the evaluation metric\n",
    "accuracy = multiclass_evaluator.evaluate(y_pred, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "precision = multiclass_evaluator.evaluate(y_pred, {multiclass_evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = multiclass_evaluator.evaluate(y_pred, {multiclass_evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = multiclass_evaluator.evaluate(y_pred, {multiclass_evaluator.metricName: \"f1\"})\n",
    "area_under_roc = binary_evaluator.evaluate(y_pred, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "# Print the metrics results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Area Under ROC: {area_under_roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/davidfrost/Documents/analytics/a3/spark/notebooks/model\" # Add path\n",
    "logreg.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "logreg = PipelineModel.load(\"/Users/davidfrost/Documents/analytics/a3/spark/notebooks/model\") # Add path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting streamed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/27 19:40:38 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "socketDF = spark.readStream.format(\"socket\").option(\"host\", \"seppe.net\").option(\"port\", 7778).load()\n",
    "socketDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import schema_of_json, from_json\n",
    "\n",
    "    # Defining process function\n",
    "def process_row(df, epoch_id):\n",
    "    print(epoch_id)\n",
    "    if df.count() == 0:\n",
    "        return\n",
    "    \n",
    "    schema = schema_of_json(df.first().value)\n",
    "    df_cols = df.selectExpr('CAST(value AS STRING)') \\\n",
    "        .select(from_json('value', schema).alias('temp')) \\\n",
    "        .select('temp.*')\n",
    "    \n",
    "    df_cols.show()\n",
    "    \n",
    "    # Apply the Pipeline model to the DataFrame and make predictions\n",
    "    predictions = logreg.transform(df_cols)\n",
    "    predictions = predictions.select('app_id','label','review_id','review_text','prediction')\n",
    "    \n",
    "    # Process the predictions\n",
    "    predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/27 19:40:38 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/wx/hpntqq5547q8b335qs5sgvcc0000gn/T/temporary-d287cf90-29ed-4429-8559-72563be0bc0a. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/05/27 19:40:38 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "0\n",
      "1\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|855740|    1|139088525|Are ya winning, s...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+------+-----+---------+--------------------+----------+\n",
      "|app_id|label|review_id|         review_text|prediction|\n",
      "+------+-----+---------+--------------------+----------+\n",
      "|855740|    1|139088525|Are ya winning, s...|       1.0|\n",
      "+------+-----+---------+--------------------+----------+\n",
      "\n",
      "2\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1581480|    0|139087527|This game is good...|\n",
      "|2409810|    1|139087687|A simple but addi...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1581480|    0|139087527|This game is good...|       0.0|\n",
      "|2409810|    1|139087687|A simple but addi...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "3\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1924400|    1|139088936|So far really fun...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1924400|    1|139088936|So far really fun...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "4\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|824600|    1|139089825|No dash, no upgra...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+------+-----+---------+--------------------+----------+\n",
      "|app_id|label|review_id|         review_text|prediction|\n",
      "+------+-----+---------+--------------------+----------+\n",
      "|824600|    1|139089825|No dash, no upgra...|       1.0|\n",
      "+------+-----+---------+--------------------+----------+\n",
      "\n",
      "5\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2307220|    0|139089074|I would rather sp...|\n",
      "|1268750|    0|139091712|installs epic gam...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|2307220|    0|139089074|I would rather sp...|       0.0|\n",
      "|1268750|    0|139091712|installs epic gam...|       0.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "6\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|    1|139091702|DO YOU WANNA LIVE...|\n",
      "|1268750|    1|139090758|So far so good, h...|\n",
      "|1268750|    1|139091203|Finally a FPS for...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1268750|    1|139091702|DO YOU WANNA LIVE...|       1.0|\n",
      "|1268750|    1|139090758|So far so good, h...|       1.0|\n",
      "|1268750|    1|139091203|Finally a FPS for...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "219\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1983710|    1|139095110|Good game, I enjo...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1983710|    1|139095110|Good game, I enjo...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "7\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1934780|    1|139090311|very good third p...|\n",
      "|1934780|    1|139089965|           good soup|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1934780|    1|139090311|very good third p...|       1.0|\n",
      "|1934780|    1|139089965|           good soup|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "8\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2008100|    1|139089680|I've been around ...|\n",
      "|1304930|    1|139091937|one of the best h...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|2008100|    1|139089680|I've been around ...|       1.0|\n",
      "|1304930|    1|139091937|one of the best h...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "9\n",
      "+-------+-----+---------+-----------+\n",
      "| app_id|label|review_id|review_text|\n",
      "+-------+-----+---------+-----------+\n",
      "|1304930|    1|139091647|        grr|\n",
      "+-------+-----+---------+-----------+\n",
      "\n",
      "+-------+-----+---------+-----------+----------+\n",
      "| app_id|label|review_id|review_text|prediction|\n",
      "+-------+-----+---------+-----------+----------+\n",
      "|1304930|    1|139091647|        grr|       1.0|\n",
      "+-------+-----+---------+-----------+----------+\n",
      "\n",
      "10\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|    1|139091414|It's very funny p...|\n",
      "|1304930|    1|139091249| wario world is good|\n",
      "|1304930|    1|139091401|Many naked dude s...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1304930|    1|139091414|It's very funny p...|       1.0|\n",
      "|1304930|    1|139091249| wario world is good|       1.0|\n",
      "|1304930|    1|139091401|Many naked dude s...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "11\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1304930|    1|139090622|The coop would be...|\n",
      "|1304930|    1|139090303|Still in early de...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1304930|    1|139090622|The coop would be...|       1.0|\n",
      "|1304930|    1|139090303|Still in early de...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "12\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 754890|    1|139088622|Maybe a tad disap...|\n",
      "|1871770|    0|139092104|I have 7 total hr...|\n",
      "|2403570|    1|139088679|Incredible level ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| 754890|    1|139088622|Maybe a tad disap...|       1.0|\n",
      "|1871770|    0|139092104|I have 7 total hr...|       0.0|\n",
      "|2403570|    1|139088679|Incredible level ...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1062810|    1|139090737|I highly recommen...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1062810|    1|139090737|I highly recommen...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "14\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1062810|    0|139090659|Bad things first....|\n",
      "|1062810|    0|139090472|I don't think I'v...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1062810|    0|139090659|Bad things first....|       0.0|\n",
      "|1062810|    0|139090472|I don't think I'v...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "15\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1062810|    1|139090033|very fun! just ha...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1062810|    1|139090033|very fun! just ha...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "16\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2141910|    1|139089852|          Its MTG :D|\n",
      "|2141910|    1|139089065|Despite what some...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|2141910|    1|139089852|          Its MTG :D|       1.0|\n",
      "|2141910|    1|139089065|Despite what some...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "17\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2141910|    1|139088439|DISCLAIMER: I hav...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|2141910|    1|139088439|DISCLAIMER: I hav...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "18\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1608230|    1|139089673|Are the puzzles p...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1608230|    1|139089673|Are the puzzles p...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "19\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1608230|    1|139089338|A beautiful audio...|\n",
      "|1608230|    1|139088968|Just beautiful an...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1608230|    1|139089338|A beautiful audio...|       1.0|\n",
      "|1608230|    1|139088968|Just beautiful an...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "20\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1649010|    1|139091704|A fantastic follo...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1649010|    1|139091704|A fantastic follo...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "21\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1649010|    1|139090368|this game was nev...|\n",
      "|1649010|    0|139090015|well i wasted £44...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1649010|    1|139090368|this game was nev...|       1.0|\n",
      "|1649010|    0|139090015|well i wasted £44...|       0.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "22\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 378760|    0|139090833|Do you like gener...|\n",
      "|2005010|    1|139092427|A brilliant boome...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| 378760|    0|139090833|Do you like gener...|       0.0|\n",
      "|2005010|    1|139092427|A brilliant boome...|       0.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "23\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|2005010|    1|139092411|literally more fu...|\n",
      "|2005010|    1|139092172|it's so good i ca...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|2005010|    1|139092411|literally more fu...|       1.0|\n",
      "|2005010|    1|139092172|it's so good i ca...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = socketDF.writeStream.trigger(processingTime='5 seconds').foreachBatch(\n",
    "    lambda df, epoch_id: process_row(df, epoch_id)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1581480|    0|139092311|Sadly i refunded....|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1581480|    0|139092311|Sadly i refunded....|       0.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n",
      "221\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1581480|    1|139091467|very good puzzle ...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "| app_id|label|review_id|         review_text|prediction|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "|1581480|    1|139091467|very good puzzle ...|       1.0|\n",
      "+-------+-----+---------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
