{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfrostcruz/advance_analytics/blob/main/testing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzNq_EzNtkxZ",
        "outputId": "7ad6010f-248c-4806-fade-46f4e20c758f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas-profiling\n",
            "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ydata-profiling (from pandas-profiling)\n",
            "  Downloading ydata_profiling-4.2.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.3/352.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.11,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.10.7)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n",
            "Collecting visions[type_image_path]==0.7.5 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.22.4)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (4.65.0)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.12.2)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.13.5)\n",
            "Collecting typeguard<3,>=2.13.2 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wordcloud>=1.9.1 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading wordcloud-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.4/455.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dacite>=1.8 (from ydata-profiling->pandas-profiling)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (8.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (3.1)\n",
            "Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling)\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2,>1.1->ydata-profiling->pandas-profiling) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling->pandas-profiling) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=b5b3434cfc6be355334b7279c0a66119cf91edaa8badd585434800041e2cef1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, multimethod, dacite, imagehash, wordcloud, visions, phik, ydata-profiling, pandas-profiling\n",
            "  Attempting uninstall: wordcloud\n",
            "    Found existing installation: wordcloud 1.8.2.2\n",
            "    Uninstalling wordcloud-1.8.2.2:\n",
            "      Successfully uninstalled wordcloud-1.8.2.2\n",
            "Successfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9.1 pandas-profiling-3.6.6 phik-0.12.3 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 visions-0.7.5 wordcloud-1.9.2 ydata-profiling-4.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: scipy<1.11,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.10.7)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (6.0)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.1.2)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.5 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.7.5)\n",
            "Requirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.22.4)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.12.3)\n",
            "Requirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.65.0)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.12.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.1)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.13.5)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.13.3)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.2)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.8.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (8.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (3.1)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2,>1.1->ydata-profiling) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autoviz\n",
            "  Downloading autoviz-0.1.604-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bokeh>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.4.3)\n",
            "Collecting emoji (from autoviz)\n",
            "  Downloading emoji-2.4.0.tar.gz (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/353.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from autoviz) (2023.4.0)\n",
            "Collecting holoviews~=1.14.9 (from autoviz)\n",
            "  Downloading holoviews-1.14.9-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hvplot>=0.7.3 (from autoviz)\n",
            "  Downloading hvplot-0.8.3-py2.py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from autoviz) (7.34.0)\n",
            "Collecting jupyter (from autoviz)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: matplotlib>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from autoviz) (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from autoviz) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.5.3)\n",
            "Requirement already satisfied: panel>=0.12.6 in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.14.4)\n",
            "Collecting pyamg (from autoviz)\n",
            "  Downloading pyamg-5.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.12.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.13.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from autoviz) (0.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from autoviz) (4.5.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.9.2)\n",
            "Requirement already satisfied: xgboost>=0.82 in /usr/local/lib/python3.10/dist-packages (from autoviz) (1.7.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from autoviz) (2.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=2.4.2->autoviz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh>=2.4.2->autoviz) (23.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=2.4.2->autoviz) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=2.4.2->autoviz) (6.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=2.4.2->autoviz) (6.3.1)\n",
            "Requirement already satisfied: param<2.0,>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (1.13.0)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (2.2.1)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from holoviews~=1.14.9->autoviz) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->autoviz) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autoviz) (2022.7.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (4.65.0)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (6.0.0)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.10/dist-packages (from panel>=0.12.6->autoviz) (67.7.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost>=0.82->autoviz) (1.10.1)\n",
            "Collecting jedi>=0.16 (from ipython->autoviz)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->autoviz) (4.8.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->autoviz) (6.4.8)\n",
            "Collecting qtconsole (from jupyter->autoviz)\n",
            "  Downloading qtconsole-5.4.3-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->autoviz) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->autoviz) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->autoviz) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->autoviz) (7.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->autoviz) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->autoviz) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->autoviz) (2022.10.31)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->autoviz) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->autoviz) (0.5.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->autoviz) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=2.4.2->autoviz) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->autoviz) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->autoviz) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->autoviz) (0.2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=0.12.6->autoviz) (0.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->autoviz) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->autoviz) (6.1.12)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->autoviz) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->autoviz) (3.0.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (4.11.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (5.3.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (0.7.4)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (5.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->autoviz) (1.2.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (21.3.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->autoviz) (0.16.0)\n",
            "Collecting qtpy>=2.0.1 (from qtconsole->jupyter->autoviz)\n",
            "  Downloading QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.12.6->autoviz) (3.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->autoviz) (3.3.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->autoviz) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->autoviz) (4.3.3)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->autoviz) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->autoviz) (2.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->autoviz) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->autoviz) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->autoviz) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->autoviz) (2.21)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.4.0-py2.py3-none-any.whl size=350809 sha256=d8cab791831d424718f0d9eec1a7c858e4d63dbc71c90180cd69d561bd7c93bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/29/1c/234cae4632803c2ba4a76a71a679eb1383cf590775714e2a21\n",
            "Successfully built emoji\n",
            "Installing collected packages: qtpy, jedi, emoji, pyamg, qtconsole, holoviews, hvplot, jupyter, autoviz\n",
            "  Attempting uninstall: holoviews\n",
            "    Found existing installation: holoviews 1.15.4\n",
            "    Uninstalling holoviews-1.15.4:\n",
            "      Successfully uninstalled holoviews-1.15.4\n",
            "Successfully installed autoviz-0.1.604 emoji-2.4.0 holoviews-1.14.9 hvplot-0.8.3 jedi-0.18.2 jupyter-1.0.0 pyamg-5.0.0 qtconsole-5.4.3 qtpy-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.13.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (23.1)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: missingno in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from missingno) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from missingno) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from missingno) (1.10.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from missingno) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->missingno) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->missingno) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->missingno) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting missingpy\n",
            "  Downloading missingpy-0.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2950 sha256=38459f2f1e497373c5ae65c6c2b475612f785abde18f21b6254e780a226426e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/1f/8d/4f812c590e074c1e928f5cec67bf5053b71f38e2648739403a\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post5\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "!pip install pandas-profiling\n",
        "!pip install ydata-profiling\n",
        "!pip install geopy\n",
        "!pip install autoviz\n",
        "!pip install matplotlib\n",
        "!pip install -U textblob\n",
        "!pip install statsmodels\n",
        "!pip install missingno\n",
        "!python -m textblob.download_corpora\n",
        "!pip install missingpy\n",
        "!pip install scikit-learn\n",
        "!pip install sklearn\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v8givaftp8O",
        "outputId": "0e79d1ee-6be9-42cc-91bf-d0d60484ab30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyDrive in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from pyDrive) (2.84.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from pyDrive) (6.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pyDrive) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pyDrive) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pyDrive) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pyDrive) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pyDrive) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pyDrive) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pyDrive) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pyDrive) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pyDrive) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.2->pyDrive) (5.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.2->pyDrive) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->pyDrive) (3.4)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Accessing drive files \n",
        "# Setting package for drive\n",
        "!pip install pyDrive\n",
        "from google.colab import files\n",
        "# Mount Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Setting up directory\n",
        "directory_path = \"/content/drive/MyDrive/analytics/data_1\"\n",
        "os.chdir(\"/content/drive/MyDrive/analytics/data_1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6D537YOGtZEl"
      },
      "outputs": [],
      "source": [
        "# Set path to the directory containing the training dataset\n",
        "path_copy_test = \"/content/drive/MyDrive/analytics/data_1/test.csv\" # add specific path\n",
        "df_test_or = pd.read_csv(path_copy_test) # Getting the original training data Set\n",
        "df_test = df_test_or.copy() # Keeping an exact copy from the data set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lKcQ5Dxm0V2a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdXx8DCzgKFG"
      },
      "source": [
        "#### Defining functions to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2_s-MrgSpRc"
      },
      "source": [
        "In this section, the used functions are defined. Make sure to run it before the rest of the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yNWEKYKsNdu"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOwuq4ITnaKQ"
      },
      "outputs": [],
      "source": [
        "# Defining numerical and categorical features of the data set \n",
        "numerical_features = [\n",
        "'property_max_guests', 'host_response_rate', 'booking_max_nights', \n",
        "'booking_min_nights', 'booking_availability_30', \n",
        "'booking_availability_60', 'booking_availability_90',\n",
        "'booking_availability_365', 'reviews_num', 'reviews_rating', 'reviews_acc', 'reviews_cleanliness',\n",
        "'reviews_checkin', 'reviews_communication', 'reviews_location',\n",
        "'reviews_value', 'reviews_per_month'\n",
        "] # Target droped\n",
        "categorical_features = [\n",
        "'property_summary', 'property_space',\n",
        "'property_desc', 'property_neighborhood', 'property_notes',\n",
        "'property_zipcode', 'property_lat', 'property_lon',\n",
        "'property_type', 'property_room_type',\n",
        "'property_bathrooms', 'property_bedrooms', 'property_beds',\n",
        "'property_bed_type', 'property_amenities', 'property_sqfeet',\n",
        "'property_last_updated', 'host_id',\n",
        "'host_location', 'host_about', 'host_response_time',\n",
        "'host_nr_listings', 'host_nr_listings_total',\n",
        "'host_verified', 'booking_price_covers', 'booking_cancel_policy',\n",
        "'extra', 'property_id', 'property_name', 'property_transit', \n",
        "'property_access', 'property_interaction', 'property_rules', \n",
        "'property_scraped_at', 'host_since', 'reviews_first', 'reviews_last'\n",
        "]\n",
        "\n",
        "text_columns = [\n",
        "    'property_name', 'property_summary', 'property_space',\n",
        "                'property_desc', 'property_neighborhood', 'property_notes',\n",
        "                'property_transit', 'property_access', 'property_interaction',\n",
        "                'property_rules'\n",
        "] # The text columns will be treated separately for featuring later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWoBmi0m5Pt5"
      },
      "outputs": [],
      "source": [
        "# Function for obtaining the descriptive statistics about the target feature\n",
        "def stats_target(df, target):\n",
        "  target_stats = df[target].describe() # Getting the target's descriptive statistics\n",
        "  stats_target_df = pd.DataFrame(target_stats) # Getting a dataframe\n",
        "  return stats_target_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzIOpUxihKsJ"
      },
      "outputs": [],
      "source": [
        "# Function for obtaining the best distribution of target variable\n",
        "from scipy import stats\n",
        "\n",
        "def find_best_distribution(data, feature):\n",
        "    # Fit different distributions to the data\n",
        "    distributions = [\n",
        "        stats.norm,  # Normal distribution\n",
        "        stats.expon,  # Exponential distribution\n",
        "        stats.gamma,  # Gamma distribution\n",
        "        stats.lognorm,  # Lognormal distribution\n",
        "        stats.beta,  # Beta distribution\n",
        "        stats.uniform  # Uniform distribution\n",
        "    ]\n",
        "\n",
        "    # Compute the AIC for each distribution\n",
        "    aic_values = []\n",
        "    for distribution in distributions:\n",
        "        params = distribution.fit(data[feature])\n",
        "        log_likelihood = distribution.logpdf(data[feature], *params).sum()\n",
        "        aic = -2 * log_likelihood + 2 * len(params)\n",
        "        aic_values.append(aic)\n",
        "\n",
        "    # Select the distribution with the lowest AIC\n",
        "    best_distribution = distributions[np.argmin(aic_values)]\n",
        "\n",
        "    # Return the name of the best fitting distribution\n",
        "    return best_distribution.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeiNegHthi9u"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def univariate_plotting(df, feature):\n",
        "    # Plot histogram with KDE\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(data=df, x=feature, kde=True, bins=30)\n",
        "    plt.xlabel('Measurement')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Histogram')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot box plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(data=df, x=feature, notch=True, sym='o')\n",
        "    plt.xlabel('Group')\n",
        "    plt.ylabel('Measurement')\n",
        "    plt.title('Box Plot')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot kernel density estimate\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.kdeplot(data=df, x=feature)\n",
        "    plt.xlabel('Measurement')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title('Kernel Density Plot')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WEYefM_lAeS"
      },
      "outputs": [],
      "source": [
        "# def plot_distribution(df, numerical_features, categorical_features):\n",
        "#     # Plot numerical features\n",
        "#     for feature in numerical_features:\n",
        "#         # Create a figure with subplots\n",
        "#         fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "#         # Plot histogram with KDE\n",
        "#         sns.histplot(data=df, x=feature, kde=True, ax=axs[0])\n",
        "#         axs[0].set_xlabel('Measurement')\n",
        "#         axs[0].set_ylabel('Frequency')\n",
        "#         axs[0].set_title('Histogram with KDE')\n",
        "\n",
        "#         # Plot box plot\n",
        "#         axs[1].boxplot(df[feature], notch=True, sym='o')\n",
        "#         axs[1].set_xlabel('Group')\n",
        "#         axs[1].set_ylabel('Measurement')\n",
        "#         axs[1].set_title('Box Plot')\n",
        "\n",
        "#         # Plot kernel density estimate\n",
        "#         sns.kdeplot(data=df, x=feature, ax=axs[2])\n",
        "#         axs[2].set_xlabel('Measurement')\n",
        "#         axs[2].set_ylabel('Density')\n",
        "#         axs[2].set_title('Kernel Density Plot')\n",
        "\n",
        "#         # Adjust the layout\n",
        "#         plt.tight_layout()\n",
        "\n",
        "#         # Show the plot\n",
        "#         plt.show()\n",
        "\n",
        "#     # Plot categorical features\n",
        "#     for feature in categorical_features:\n",
        "#         # Create a count plot\n",
        "#         sns.countplot(data=df, x=feature)\n",
        "#         plt.xlabel('Categories')\n",
        "#         plt.ylabel('Count')\n",
        "#         plt.title('Count Plot')\n",
        "#         plt.xticks(rotation=90)\n",
        "#         plt.tight_layout()\n",
        "\n",
        "#         # Show the plot\n",
        "#         plt.show()\n",
        "\n",
        "# # Usage example\n",
        "# plot_distribution(df, numerical_features, categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n34W-0UU4dKF"
      },
      "outputs": [],
      "source": [
        "# Definying a function for correlation identification with heatmap visualization\n",
        "def correlation_heatmap(df):\n",
        "    # Getting correlation matrix\n",
        "    corr_matrix = df.corr()\n",
        "    # Print correlation matrix\n",
        "    print(\"Correlation Matrix:\\n\", corr_matrix.to_string())\n",
        "    # Create heatmap plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, vmin=-1, vmax=1, fmt='.1f')\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnvimBTC5cws"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "# Defining a function for doing clustering on two categorical features\n",
        "def plot_dendrogram(dataframe):\n",
        "    # Compute the linkage matrix using Ward's method\n",
        "    linkage_matrix = linkage(dataframe, method='ward')\n",
        "\n",
        "    # Plot the dendrogram\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    dendrogram(linkage_matrix)\n",
        "    plt.xlabel('Locations')\n",
        "    plt.ylabel('Distance')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzzbvTUIm6FH"
      },
      "outputs": [],
      "source": [
        "# Getting the accurate types for the features within the data set \n",
        "def convert_correct_types(df):\n",
        "    if df['property_bedrooms'].dtype == 'float64':\n",
        "        df['property_bedrooms'] = df['property_bedrooms'].fillna(np.NaN).astype('Int64')\n",
        "    if df['property_beds'].dtype == 'float64':\n",
        "        df['property_beds'] = df['property_beds'].fillna(np.NaN).astype('Int64')\n",
        "    if df['booking_price_covers'].dtype == 'float64':\n",
        "        df['booking_price_covers'] = df['booking_price_covers'].fillna(np.NaN).astype('Int64')\n",
        "    if df['host_response_rate'].dtype == 'float64':\n",
        "        df['host_response_rate'] = df['host_response_rate'].fillna(np.NaN).astype('Int64')\n",
        "    return df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2OKU8eInCsJ"
      },
      "outputs": [],
      "source": [
        "# Making content of zipcode homogeneous \n",
        "def convert_zipcode(df):\n",
        "    if df['property_zipcode'].dtype == 'object':\n",
        "        df['property_zipcode'] = df['property_zipcode'].str.strip()\n",
        "        df['property_zipcode'] = df['property_zipcode'].str.replace(' ', '')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUTcMP_gqh8q"
      },
      "outputs": [],
      "source": [
        "# Defining function for identifying identical features\n",
        "def duplicate_features(data):\n",
        "    duplicates = set()  \n",
        "    kept_features = []\n",
        "    removed_features = []  \n",
        "\n",
        "    for i, column1 in enumerate(data.columns):  \n",
        "        for j, column2 in enumerate(data.columns[i + 1:], i + 1):\n",
        "            # Checking if column1 and column2 are equal\n",
        "            if data[column1].equals(data[column2]):\n",
        "                # If they are equal, add column2 to the duplicates set\n",
        "                duplicates.add(column2)\n",
        "                # Get the kept feature \n",
        "                kept_feature = data.columns[i]\n",
        "                kept_features.append(kept_feature)  # List of the kept features\n",
        "                removed_features.append(column2)\n",
        "\n",
        "                # Print the duplicated feature\n",
        "                print(f\"Feature '{column2}' is duplicated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef46eUGm3D57"
      },
      "source": [
        "Missigness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTZOcPa4n8Lf"
      },
      "outputs": [],
      "source": [
        "# Defining function for recognizing missing values within features\n",
        "def features_missing_values(df):\n",
        "    missing = df.isnull().sum() # Identifying missing sum within each feature\n",
        "    missing_pct = (missing / len(df)) * 100 # Percentage of missingness compare to total n in dataset\n",
        "    missing_values = pd.concat([\n",
        "        missing, missing_pct.astype('int64')], # Getting type int64 for Percentage column \n",
        "        axis=1, \n",
        "        keys=[\n",
        "            'Total Missing', 'Percentage (%)']\n",
        "     ) # Creating dataframe with % of missing for each feature\n",
        "    missing_values.sort_values(by='Total Missing', ascending=False, inplace=True)\n",
        "    missing_values.index.name = 'Feature'\n",
        "    return missing_values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E-ZiLf1dT7X"
      },
      "outputs": [],
      "source": [
        "# Defining function for identifying the features with missing rates greater than 90%\n",
        "def identify_missing_features(data, threshold=0.9):\n",
        "    missing_perc = data.isnull().sum() / len(data) * 100  # Calculate the percentage of missingness within each feature\n",
        "    high_missing_features = missing_perc[missing_perc >= threshold * 100].index.tolist()  # Features with missing rate >= 90%\n",
        "\n",
        "    if not high_missing_features:\n",
        "        print(\"No features with missingness rate greater than {}% found. The default threshold is 90%.\".format(threshold * 100))\n",
        "    else:\n",
        "        print(\"The following features have a missing rate greater than {}%:\".format(threshold * 100))\n",
        "        for feature in high_missing_features:\n",
        "            print(\"- {}\".format(feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sJq24Kn42xE"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def impute_missing_values(df):\n",
        "    imputed_df = df.copy()\n",
        "\n",
        "    numerical_features_remaining = [col for col in numerical_features if col in imputed_df.columns]\n",
        "    categorical_features_remaining = [col for col in categorical_features if col in imputed_df.columns]\n",
        "\n",
        "    knn_imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "    imputed_numerical = knn_imputer.fit_transform(imputed_df[numerical_features_remaining])\n",
        "    imputed_numerical_df = pd.DataFrame(imputed_numerical, columns=numerical_features_remaining)\n",
        "    imputed_numerical_df[numerical_features_remaining] = imputed_numerical_df[numerical_features_remaining].astype(imputed_df[numerical_features_remaining].dtypes)\n",
        "\n",
        "    imputed_df[numerical_features_remaining] = imputed_numerical_df[numerical_features_remaining]\n",
        "\n",
        "    categorical_features_to_impute = [col for col in categorical_features_remaining if col not in text_columns]\n",
        "    mode_imputers = {}\n",
        "    for col in categorical_features_to_impute:\n",
        "        mode_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        imputed_df[col] = mode_imputer.fit_transform(imputed_df[col].values.reshape(-1, 1))\n",
        "        mode_imputers[col] = mode_imputer\n",
        "\n",
        "    imputed = (df[numerical_features_remaining] != imputed_numerical_df[numerical_features_remaining]).any(axis=1)\n",
        "    imputed_df['imputed'] = imputed.astype('int64')\n",
        "\n",
        "    return imputed_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S1PA_ss52f_"
      },
      "source": [
        "outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LceJ1ZeS53Qp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "# Defining function doing one-hot encoding on categorical features\n",
        "def encode_categorical_features(df, categorical_features):\n",
        "    # Perform one-hot encoding on the categorical features\n",
        "    encoder = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
        "    onehot = encoder.fit_transform(df[categorical_features])\n",
        "    onehot_labels = encoder.get_feature_names_out(categorical_features)\n",
        "\n",
        "    # Creating a new DataFrame with the encoded features\n",
        "    df_onehot = pd.DataFrame.sparse.from_spmatrix(onehot, columns=onehot_labels)\n",
        "\n",
        "    return df_onehot\n",
        "  \n",
        "# Defining function for identifying outliers\n",
        "def perform_outlier_detection(df, numerical_features, categorical_features, text_columns):\n",
        "    # Filtering the numerical and categorical features\n",
        "    numerical_features_remaining = [col for col in numerical_features if col in df.columns]\n",
        "    categorical_features_remaining = [col for col in categorical_features if col in df.columns]\n",
        "    features = numerical_features_remaining + list(df.columns[df.columns.str.startswith('x')]) # This excludes the text columns\n",
        "\n",
        "    # Encoding categorical features (excluding text columns)\n",
        "    encoded_df = encode_categorical_features(df[categorical_features_remaining], categorical_features_remaining)\n",
        "\n",
        "    # Selecting the features\n",
        "    features = [col for col in features if col in encoded_df.columns]\n",
        "\n",
        "    # Performing outlier detection using Local Outlier Factor (LOF)\n",
        "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.02)\n",
        "    y_pred = lof.fit_predict(pd.concat([encoded_df[features], df[numerical_features_remaining]], axis=1))\n",
        "\n",
        "    # Creating a new column to store outlier\n",
        "    df['is_outlier'] = y_pred\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_outlier_detection(df):\n",
        "    # Plotting the numerical features against each other\n",
        "    sns.pairplot(df, vars=numerical_features, hue='is_outlier', plot_kws={'alpha': 0.6})\n",
        "\n",
        "    # Adding legend\n",
        "    plt.legend(title='Outlier', labels=['Normal', 'Outlier'])\n",
        "\n",
        "    # Adjusting the layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-d4nFYgOZqKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-f6IH65tx7m"
      },
      "source": [
        "featuring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HKmm8YFty7T"
      },
      "outputs": [],
      "source": [
        "# Create dummy column for every 'extra' (1 or 0 if property has this extra or not)\n",
        "def add_and_populate_columns_for_extras(df):\n",
        "  #step 1: sum up all possible amenities\n",
        "  extras = [] #empty list\n",
        "  for index,row in df.iterrows(): #loop over rows\n",
        "    row_as_list = str(row['extra']).split(sep=', ') #split string seperate amenities (returns list)\n",
        "    for extra in row_as_list: #loop over seperate amenities in list\n",
        "      if not extra in extras and extra != 'nan': #for every (new) amenity, check whether it is already in the list, add if not\n",
        "        extras.append(extra)\n",
        "\n",
        "  #step 2: create and populate columns in df\n",
        "  print(extras)\n",
        "  for extra in extras:\n",
        "    df['dummy_extra_' + extra] = df.apply(lambda x: extra in str(x['extra']).split(sep=', '), axis=1).astype(int) #loop over unique amenities and check whether string contains this amenity, if so, returns True (dummy=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LznJx6cAwNat"
      },
      "outputs": [],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "# Defining function for getting the zipcode from latitude and longitude on the missing values for those features \n",
        "# Getting a geolocator using Nominatim\n",
        "geolocator = Nominatim(user_agent=\"zipcode2\", timeout=10)\n",
        "\n",
        "def add_zipcode2_column(df):\n",
        "    if \"zipcode2\" in df.columns:\n",
        "        print(\"Column 'zipcode2' already exists. Skipping computation.\")\n",
        "        return df\n",
        "    else: # If the code has ran already and feature was created, no procedure is done\n",
        "    # If feature has been created, then getting the zipcode from the coordinates on the data set. Make sure to define the same name on the features :)\n",
        "        def get_zipcode2(row):\n",
        "            if pd.notnull(row['property_zipcode']): # If the row has already the zipcode, keep it \n",
        "                return row['property_zipcode'].replace(\" \", \"\") #delete spaces\n",
        "            else: # If row does not have a zipcode, then obtaining it from the coordinates\n",
        "                lat = row['property_lat']\n",
        "                lon = row['property_lon']\n",
        "                if pd.notnull(lat) and pd.notnull(lon):\n",
        "                    location = geolocator.reverse(f\"{lat},{lon}\", exactly_one=True)\n",
        "                    address = location.raw['address']\n",
        "                    return address.get('postcode')\n",
        "                else:\n",
        "                    return None\n",
        "                    t\n",
        "        df['zipcode2'] = df.apply(get_zipcode2, axis=1)\n",
        "        print(\"Column 'zipcode2' added to DataFrame.\")\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFuNgICWfjz4"
      },
      "outputs": [],
      "source": [
        "def city(data):\n",
        "    for index, row in data.iterrows():\n",
        "        zipcode = str(row['zipcode2'])\n",
        "        if zipcode.startswith(\"1\"):\n",
        "            data.loc[index, 'city'] = \"Brussels\"\n",
        "        elif zipcode.startswith(\"2\"):\n",
        "            data.loc[index, 'city'] = \"Antwerp\"\n",
        "        else:\n",
        "            data.loc[index, 'city'] = \"Unknown\"\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_rooms(df):\n",
        "    grouped_df = df.copy()\n",
        "\n",
        "    # Create a new feature for room configuration\n",
        "    grouped_df['room_configuration'] = ''\n",
        "\n",
        "    # Iterate over each row\n",
        "    for index, row in grouped_df.iterrows():\n",
        "        num_bathrooms = row['property_bathrooms']\n",
        "        num_bedrooms = row['property_bedrooms']\n",
        "        num_beds = row['property_beds']\n",
        "\n",
        "        # Determine the room configuration based on the number of rooms\n",
        "        if num_bathrooms == 1 and num_bedrooms == 1 and num_beds == 1:\n",
        "            grouped_df.loc[index, 'room_configuration'] = '1B1B1B'  # 1 Bathroom, 1 Bedroom, 1 Bed\n",
        "        elif num_bathrooms >= 2 and num_bedrooms >= 2 and num_beds >= 2:\n",
        "            grouped_df.loc[index, 'room_configuration'] = '2B2B2B+'  # 2 or more Bathrooms, 2 or more Bedrooms, 2 or more Beds\n",
        "        else:\n",
        "            grouped_df.loc[index, 'room_configuration'] = 'Other'  # Other room configurations\n",
        "\n",
        "    # Drop the individual room count columns if desired\n",
        "    # grouped_df.drop(['Number of Bathrooms', 'Number of Bedrooms', 'Number of Beds'], axis=1, inplace=True)\n",
        "\n",
        "    return grouped_df"
      ],
      "metadata": {
        "id": "vDtDcZHVhfjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_guests_to_rooms_ratio(df):\n",
        "    # Calculate the sum of bathrooms, bedrooms, and beds\n",
        "    df['rooms_sum'] = df['property_bathrooms'] + df['property_bedrooms'] + df['property_beds']\n",
        "\n",
        "    # Calculate the guests to rooms ratio\n",
        "    df['guests_to_rooms_ratio'] = df['property_max_guests'] / df['rooms_sum']\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "kEkr8o8RhxUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_boolean_column(df, columns, new_column_name):\n",
        "    df[new_column_name] = (df[columns] == 1).any(axis=1).astype(int)\n",
        "    return df"
      ],
      "metadata": {
        "id": "o4TiyvODe69O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_property_amenities(df):\n",
        "    # Define categories and keywords/patterns\n",
        "    categories = {\n",
        "        'Kitchen': ['kitchen'],\n",
        "        'Entertainment': ['cable', 'tv'],\n",
        "        'Safety': ['smoke detector', 'carbon monoxide detector', 'first aid kit', 'fire extinguisher'],\n",
        "        'Internet': ['internet', 'wireless internet'],\n",
        "        'Pets': ['pet', 'dog', 'cat'],\n",
        "        'Other amenities': []\n",
        "    }\n",
        "\n",
        "    # Group amenities into categories\n",
        "    grouped_amenities = {category: [] for category in categories.keys()}\n",
        "    default_category = 'Other amenities'\n",
        "\n",
        "    for amenities in df['property_amenities']:\n",
        "        if isinstance(amenities, str):\n",
        "            for amenity in amenities.split(','):\n",
        "                amenity = amenity.strip()\n",
        "                for category, keywords in categories.items():\n",
        "                    if any(re.search(keyword, amenity, re.IGNORECASE) for keyword in keywords):\n",
        "                        grouped_amenities[category].append(amenity)\n",
        "                        break\n",
        "                else:\n",
        "                    grouped_amenities[default_category].append(amenity)\n",
        "\n",
        "    # Create binary features for each category\n",
        "    for category, amenities in grouped_amenities.items():\n",
        "        df[category] = df['property_amenities'].apply(lambda x: int(any(amenity in x for amenity in amenities)))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uoolSd5po9w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def calculate_host_duration(df, host_since_column='host_since'):\n",
        "    # Convert the host start dates to datetime objects\n",
        "    df[host_since_column] = pd.to_datetime(df[host_since_column])\n",
        "\n",
        "    # Calculate the duration by subtracting the host start dates from the current date\n",
        "    df['host_duration'] = (datetime.now() - df[host_since_column]).dt.days\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "7rdSGnuMpPd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTkoKbZ16mOL"
      },
      "source": [
        "model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTyyg9gVweC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# Defining function for getting the metrics for doing model selection\n",
        "def score_estimator(estimator, X_test, y_test):\n",
        "    \"\"\"Score an estimator on the test set.\"\"\"\n",
        "    y_pred = np.round(estimator.predict(X_test))\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Print each of the metrics\n",
        "    print(\"MSE: %.3f\" % mse)\n",
        "    print(\"RMSE: %.3f\" % rmse)\n",
        "    print(\"MAE: %.3f\" % mae)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to run this line before\n",
        "df = df_test"
      ],
      "metadata": {
        "id": "nYVJAGKl00jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcR0CNwBl61j"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVaGvGc_mXN2"
      },
      "source": [
        "## Data Cleaning and data consistency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5vE8J1NmyNw"
      },
      "outputs": [],
      "source": [
        "# Making values from zipcode uniform\n",
        "df = convert_zipcode(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk3tv1JZ-NBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f6050c-9a72-40a0-94e2-acaa6c0c2440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'host_nr_listings_total' is duplicated.\n"
          ]
        }
      ],
      "source": [
        "duplicate_features(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GuMOiLs-rkz"
      },
      "outputs": [],
      "source": [
        "df = df.drop('host_nr_listings_total', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KdhlMAKqHxr"
      },
      "source": [
        "## Dealing with missigness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxv5svMqqLHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968a84b8-26a4-4371-8519-8ac680e2b276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following features have a missing rate greater than 90.0%:\n",
            "- property_sqfeet\n"
          ]
        }
      ],
      "source": [
        "identify_missing_features(df, threshold=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeBmx4NP_lvy"
      },
      "outputs": [],
      "source": [
        "df = df.drop('property_sqfeet', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed = impute_missing_values(df)"
      ],
      "metadata": {
        "id": "Fhq-uee0XxAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpRoxVPY4kvL"
      },
      "source": [
        "## Dealing with outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEHGJntqGtjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64d7c47-e3f7-4b14-aacb-6645e077462e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Perform one-hot encoding and outlier detection\n",
        "df_out = perform_outlier_detection(df_imputed, numerical_features, categorical_features, text_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHG_BiCd4j8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728c4329-56a5-4236-bb34-94b0671b70c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1    6365\n",
            "-1     130\n",
            "Name: is_outlier, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# count the unique values of a feature\n",
        "unique_counts = df_out['is_outlier'].value_counts()\n",
        "\n",
        "# print the unique value counts\n",
        "print(unique_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9LYaRNNGuAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a8d06f-750b-4ed6-d504-d46bf44babec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed rows:\n",
            "[26, 195, 199, 244, 245, 275, 357, 383, 442, 450, 511, 583, 661, 721, 814, 818, 916, 1015, 1199, 1263, 1283, 1284, 1285, 1295, 1326, 1386, 1395, 1396, 1397, 1398, 1399, 1416, 1435, 1469, 1505, 1648, 1701, 1895, 1940, 1970, 1987, 1988, 2033, 2095, 2131, 2135, 2137, 2184, 2198, 2199, 2263, 2299, 2311, 2413, 2422, 2487, 2488, 2574, 2590, 2768, 2805, 2809, 2859, 2939, 3019, 3096, 3104, 3137, 3200, 3201, 3202, 3586, 3606, 3661, 3744, 3753, 3918, 3981, 4111, 4388, 4430, 4432, 4481, 4544, 4545, 4589, 4639, 4642, 4653, 4716, 4802, 4900, 4994, 5187, 5272, 5310, 5311, 5316, 5317, 5318, 5397, 5445, 5458, 5506, 5525, 5529, 5530, 5598, 5599, 5614, 5644, 5848, 5949, 5953, 5954, 5959, 5961, 6008, 6051, 6084, 6113, 6162, 6198, 6200, 6201, 6202, 6233, 6329, 6347, 6365]\n"
          ]
        }
      ],
      "source": [
        "removed_rows = df_out[df_out['is_outlier'] == -1].index.tolist()\n",
        "df_out = df_out[df_out['is_outlier'] != -1]\n",
        "df_imputed = df_imputed.drop(removed_rows)\n",
        "df = df_imputed\n",
        "print(\"Removed rows:\")\n",
        "print(removed_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncoment if you want to perform it on obs <200 for the target"
      ],
      "metadata": {
        "id": "GHDU1_WGx_cY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qwMFbwqc5gz"
      },
      "outputs": [],
      "source": [
        "# df = df[df['target'] <= 200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUVPXqXJAcpY"
      },
      "source": [
        "## Creating features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA8oE4fIpGZD"
      },
      "outputs": [],
      "source": [
        "# Condition to check for text by row\n",
        "has_text = df[text_columns].apply(lambda row: 0 if any(pd.isna(row)) or any(row == ' ') or any(row == ' ') else 1, axis=1)\n",
        "\n",
        "# Assign value to text_var based on the condition\n",
        "df['text_var'] = has_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyU23YwJqRL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afbac55-892d-4c51-f270-18d08695d8af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5260\n",
              "1    1105\n",
              "Name: text_var, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df['text_var'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odjvwr4fvAOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff00979-bcca-46e3-892b-a8d12a2eccf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "6490    0\n",
            "6491    0\n",
            "6492    0\n",
            "6493    0\n",
            "6494    1\n",
            "Name: property_room_type, Length: 6365, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# encode property_room_type into entire home/apt vs other\n",
        "def binary_property_room_type(row):\n",
        "    if row['property_room_type'] == 'Entire home/apt': \n",
        "        return 1\n",
        "    else:\n",
        "        return 0 \n",
        "df['property_room_type'] = df.apply(lambda x: binary_property_room_type(x), axis=1)\n",
        "\n",
        "print(df.property_room_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S9exMwFsEdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f40553c-f944-4147-cfd9-d95c7b4c8c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        9.666667\n",
            "1        9.666667\n",
            "2        9.500000\n",
            "3       10.000000\n",
            "4       10.000000\n",
            "          ...    \n",
            "6490    10.000000\n",
            "6491     9.533333\n",
            "6492     9.500000\n",
            "6493     9.666667\n",
            "6494     9.400000\n",
            "Name: reviews_avg, Length: 6365, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Setting an index for reviews: 'reviews_acc', 'reviews_cleanliness', 'reviews_checkin', 'reviews_communication', 'reviews_location', 'reviews_value'\n",
        "df['reviews_avg'] = df[['reviews_acc', 'reviews_cleanliness', 'reviews_checkin', 'reviews_communication', 'reviews_location', 'reviews_value']].mean(axis=1)\n",
        "print(df.reviews_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-MT1gPggg_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5868c8e0-5a5f-476d-abaa-3049cc8f8944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'zipcode2' added to DataFrame.\n"
          ]
        }
      ],
      "source": [
        "df = add_zipcode2_column(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = city(df)"
      ],
      "metadata": {
        "id": "LvEzQINnL3ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amjBitntVbzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0726863-46af-409b-fb2b-9fc603073ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Host Has Profile Pic', 'Is Location Exact', 'Instant Bookable', 'Host Is Superhost', 'Host Identity Verified', 'Require Guest Phone Verification', 'Require Guest Profile Picture']\n"
          ]
        }
      ],
      "source": [
        "add_and_populate_columns_for_extras(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['city'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTiOKhUqTUuP",
        "outputId": "d2ad32f5-0d2c-4e30-e83e-cbe80afdcf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brussels    5310\n",
              "Antwerp     1055\n",
              "Name: city, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.distance import geodesic\n",
        "\n",
        "def add_distance_to_city_center(df, city_center_coords, city_column='city'):\n",
        "    for city, coords in city_center_coords.items():\n",
        "        city_mask = df[city_column] == city\n",
        "        df.loc[city_mask, 'distance_to_city_center'] = df[city_mask].apply(\n",
        "            lambda row: geodesic((row['property_lat'], row['property_lon']), coords).kilometers,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "# Usage example\n",
        "city_center_coords = {\n",
        "    'Brussels': (50.8503, 4.3517),\n",
        "    'Antwerp': (51.2194, 4.4025)\n",
        "}\n",
        "\n",
        "add_distance_to_city_center(df, city_center_coords)"
      ],
      "metadata": {
        "id": "62Siq2_3CR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_check = ['dummy_extra_Is Location Exact', 'dummy_extra_Instant Bookable', 'dummy_extra_Host Identity Verified', 'dummy_extra_Host Is Superhost']\n",
        "new_column_name = 'ext'\n",
        "\n",
        "df = create_combined_boolean_column(df, columns_to_check, new_column_name)"
      ],
      "metadata": {
        "id": "HzkhUTltR9ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = group_rooms(df)"
      ],
      "metadata": {
        "id": "cSwHtvXydx1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def calculate_host_duration(df, host_since_column='host_since'):\n",
        "    # Convert the host start dates to datetime objects\n",
        "    df[host_since_column] = pd.to_datetime(df[host_since_column])\n",
        "\n",
        "    # Calculate the duration by subtracting the host start dates from the current date\n",
        "    df['host_duration'] = (datetime.now() - df[host_since_column]).dt.days\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "hoLhtreQdvAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = calculate_host_duration(df)"
      ],
      "metadata": {
        "id": "aiQZcSP1fafM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = calculate_guests_to_rooms_ratio(df)"
      ],
      "metadata": {
        "id": "hIuwJHnUh31A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = group_property_amenities(df)"
      ],
      "metadata": {
        "id": "1cNxm6mWmyT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_booking_rate(df):\n",
        "    df['booking_rate'] = df['booking_max_nights'] - df['booking_min_nights'] / df['booking_availability_365']\n",
        "    df['booking_rate'] = df['booking_rate'].replace([np.inf, -np.inf], 0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "kHzb1sIho4Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = calculate_booking_rate(df)"
      ],
      "metadata": {
        "id": "_E4b8W4WqAOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JvDwkhZAvX6"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JeH2u-TRnhox"
      },
      "outputs": [],
      "source": [
        "set_up = df[[\n",
        "    'reviews_avg', 'booking_rate', 'reviews_per_month', 'guests_to_rooms_ratio', 'host_response_rate', 'host_duration', 'distance_to_city_center',\n",
        "    'room_configuration', 'property_room_type', 'Entertainment',\n",
        "]] # Same set-up, but target is excluded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XhDxXjAbt8xn"
      },
      "outputs": [],
      "source": [
        "# Load the model from the file\n",
        "filename = '/content/drive/MyDrive/analytics/data_1/model.pkl' ad\n",
        "with open(filename, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bGAjsi235oRt"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = loaded_model.predict(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOFpgKh+PlSSs7bvm9NUc7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}